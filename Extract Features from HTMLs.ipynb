{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "There are many features that we want to extract from the websites:\n",
    "\n",
    "* Size (total, text, css, js) - we have to ignore css and js for now, since we don't have them\n",
    "* Number of images\n",
    "* Number of forms\n",
    "* Number of mailto links\n",
    "* Bag of words (the whole website)\n",
    "* Only specific words (based on tags)\n",
    "* Number of items in navigation menu\n",
    "* Navigation menu\n",
    "* Meta description\n",
    "* Meta keywords\n",
    "\n",
    "Optionally, we might want to extend this to:\n",
    "\n",
    "* Topics (that we extract)\n",
    "* Genres of the sites (extracted as well)\n",
    "* Check for iframes, Bootstrap, React, etc.\n",
    "* Check for Google Analytics\n",
    "* Check for Facebook/Twitter/Google+ meta elements\n",
    "* How much are HTML5 and CSS3 elements used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('companies_cross.json', 'r') as f:\n",
    "    companies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use only companies that we currently have website of (at least some pages)\n",
    "companies = [c for c in companies if c.get('path_to')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get bag of words for websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:24<00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "from scandir import walk\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "# Some helper functions\n",
    "def get_soup_from_html_gz(path):\n",
    "    with gzip.open(path, 'rt') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "texts = []\n",
    "hv = HashingVectorizer()\n",
    "for company in tqdm(companies[:1000]):\n",
    "    text = ''\n",
    "    path = company['path_to']\n",
    "    for dirpath, dirs, file_names in walk(path):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith('.gz'):\n",
    "                text += get_soup_from_html_gz(os.path.join(dirpath, file_name)).get_text()\n",
    "                text += '\\n'\n",
    "    \n",
    "    # NOTE: It might be better to first extract text, save it in file, then pass list of paths to HashingVectorizer\n",
    "    texts.append(text)\n",
    "bag = hv.transform(texts)\n",
    "del texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1218460 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract different features from websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:02<00:10,  7.91it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "from scandir import walk\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Some helper functions\n",
    "def get_soup_from_html_gz(path):\n",
    "    with gzip.open(path, 'rt') as f:\n",
    "        soup = BeautifulSoup(f, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "image_counts = []\n",
    "hv = HashingVectorizer()\n",
    "for company in tqdm(companies[:100]):\n",
    "    image_count = 0\n",
    "    sites = 0\n",
    "    path = company['path_to']\n",
    "    for dirpath, dirs, file_names in walk(path):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith('.gz'):\n",
    "                sites += 1\n",
    "                image_count += len(get_soup_from_html_gz(os.path.join(dirpath, file_name)).find_all('form'))                \n",
    "    image_counts.append(image_count / sites if sites else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51.81818181818182,\n",
       " 1.5,\n",
       " 8.571428571428571,\n",
       " 9.0,\n",
       " 4.857142857142857,\n",
       " 0.0,\n",
       " 9.0,\n",
       " 8.25,\n",
       " 5.5,\n",
       " 8.333333333333334,\n",
       " 11.11111111111111,\n",
       " 0,\n",
       " 9.5,\n",
       " 19.545454545454547,\n",
       " 8.0,\n",
       " 8.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 7.0,\n",
       " 6.2,\n",
       " 2.0,\n",
       " 3.3333333333333335,\n",
       " 28.72222222222222,\n",
       " 2.3846153846153846,\n",
       " 1.0,\n",
       " 1.8571428571428572,\n",
       " 7.666666666666667,\n",
       " 0,\n",
       " 14.333333333333334,\n",
       " 23.0,\n",
       " 13.0,\n",
       " 3.3333333333333335,\n",
       " 3.0,\n",
       " 11.678571428571429,\n",
       " 12.1,\n",
       " 4.0,\n",
       " 12.666666666666666,\n",
       " 6.25,\n",
       " 27.6,\n",
       " 34.875,\n",
       " 19.571428571428573,\n",
       " 11.714285714285714,\n",
       " 0.0,\n",
       " 12.7,\n",
       " 13.0,\n",
       " 0,\n",
       " 7.875,\n",
       " 19.88888888888889,\n",
       " 19.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 5.5,\n",
       " 11.818181818181818,\n",
       " 7.75,\n",
       " 7.8,\n",
       " 8.0,\n",
       " 12.5,\n",
       " 3.3333333333333335,\n",
       " 2.2,\n",
       " 14.166666666666666,\n",
       " 3.1818181818181817,\n",
       " 5.142857142857143,\n",
       " 3.625,\n",
       " 69.33333333333333,\n",
       " 9.0,\n",
       " 13.0,\n",
       " 5.428571428571429,\n",
       " 0,\n",
       " 15.142857142857142,\n",
       " 10.0,\n",
       " 16.333333333333332,\n",
       " 17.375,\n",
       " 2.3333333333333335,\n",
       " 0,\n",
       " 9.090909090909092,\n",
       " 10.583333333333334,\n",
       " 5.181818181818182,\n",
       " 22.142857142857142,\n",
       " 3.2857142857142856,\n",
       " 0.0,\n",
       " 34.111111111111114,\n",
       " 5.0,\n",
       " 0.5,\n",
       " 2.0,\n",
       " 9.333333333333334,\n",
       " 2.0,\n",
       " 33.142857142857146,\n",
       " 63.2,\n",
       " 11.0,\n",
       " 1.25,\n",
       " 28.5,\n",
       " 4.181818181818182,\n",
       " 45.875,\n",
       " 4.0,\n",
       " 11.833333333333334,\n",
       " 7.0,\n",
       " 16.0,\n",
       " 4.4,\n",
       " 0,\n",
       " 10.571428571428571]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
