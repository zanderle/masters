{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('companies_cross.json', 'r') as f:\n",
    "    companies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Let's use only companies that we currently have website of (at least some pages)\n",
    "companies = [c for c in companies if c.get('path_to')]\n",
    "\n",
    "# Let's also limit the number of sites (because this is not cleaned yet)\n",
    "companies = [c for c in companies if c.get('current_site_count', 0) < 100]\n",
    "\n",
    "# Let's use only well represented industries\n",
    "industries = Counter([c['industry'] for c in companies])\n",
    "companies = [c for c in companies if industries[c.get('industry')] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "\n",
    "# set root logger level\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# setup custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.FileHandler('extract_features.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def get_texts_for_domain(path, file_name):\n",
    "    text_file = os.path.join(path, file_name)\n",
    "    if not os.path.exists(text_file) or force_read:\n",
    "        text = None\n",
    "        text_file = '/dev/null'\n",
    "    else:\n",
    "        with open(text_file, 'r') as f:\n",
    "            text = f.read()\n",
    "    return text, text_file\n",
    "\n",
    "\n",
    "def get_full_text(path):\n",
    "    return get_texts_for_domain(path, 'full_texts.txt')\n",
    "\n",
    "\n",
    "def get_nav_text(path):\n",
    "    return get_texts_for_domain(path, 'nav_menu.txt')\n",
    "\n",
    "\n",
    "def get_meta_descriptions_text(path):\n",
    "    return get_texts_for_domain(path, 'descriptions.txt')\n",
    "\n",
    "\n",
    "def get_meta_keywords_text(path):\n",
    "    return get_texts_for_domain(path, 'keywords.txt')\n",
    "\n",
    "\n",
    "def get_titles_text(path):\n",
    "    return get_texts_for_domain(path, 'titles.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformers\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_from_company(companies, func):\n",
    "    paths = []\n",
    "    for company in tqdm(companies):\n",
    "        text, file_path = func(company['path_to'])\n",
    "        paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_full_text_from_company(companies):\n",
    "    return extract_from_company(companies, get_full_text)\n",
    "\n",
    "def get_nav_menus_from_company(companies):\n",
    "    return extract_from_company(companies, get_nav_text)\n",
    "\n",
    "def get_descriptions_from_company(companies):\n",
    "    return extract_from_company(companies, get_meta_descriptions_text)\n",
    "\n",
    "def get_titles_from_company(companies):\n",
    "    return extract_from_company(companies, get_titles_text)\n",
    "\n",
    "\n",
    "full_text_transformer = FunctionTransformer(get_full_text_from_company, validate=False)\n",
    "nav_menus_transformer = FunctionTransformer(get_nav_menus_from_company, validate=False)\n",
    "descriptions_transformer = FunctionTransformer(get_descriptions_from_company, validate=False)\n",
    "titles_transformer = FunctionTransformer(get_titles_from_company, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "hv = HashingVectorizer(non_negative=True, input='filename')\n",
    "tf_transformer = TfidfTransformer()\n",
    "clf = SGDClassifier(loss='hinge', n_iter=100, alpha=0.01, n_jobs=10)\n",
    "\n",
    "pipeline_elements = [('HV', hv), ('tfid', tf_transformer), ('svc', clf)]\n",
    "pipe = Pipeline(pipeline_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "pipe_full = Pipeline([('Full', full_text_transformer)] + pipeline_elements)\n",
    "pipe_nav_menus = Pipeline([('Navs', nav_menus_transformer)] + pipeline_elements)\n",
    "pipe_descriptions = Pipeline([('Descriptions', descriptions_transformer)] + pipeline_elements)\n",
    "pipe_titles = Pipeline([('Titles', titles_transformer)] + pipeline_elements)\n",
    "\n",
    "voting = VotingClassifier(estimators=[('full', pipe_full),\n",
    "                                      ('navs', pipe_nav_menus),\n",
    "                                      ('desc', pipe_descriptions),\n",
    "                                      ('titles', pipe_titles)],\n",
    "                         voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "companies = shuffle(companies)\n",
    "train_data = companies[:100000]\n",
    "\n",
    "target = [company['industry'] for company in train_data]\n",
    "\n",
    "voting.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = companies[-8000:]\n",
    "\n",
    "score = voting.score(test_data, [c['industry'] for c in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "print(\"Classification report for classifier:\\n%s\\n\"\n",
    "      % classification_report(expected, predicted))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_count = Counter(expected)\n",
    "results = {}\n",
    "for num, example in enumerate(expected):\n",
    "    if example == predicted[num]:\n",
    "        results[example] = results.get(example, 0) + 1\n",
    "    elif predicted[num] in similar_industries.get(example, []):\n",
    "        results[example] = results.get(example, 0) + 0.5\n",
    "\n",
    "for key, value in results.items():\n",
    "    results[key] = value / expected_count[key]\n",
    "\n",
    "print(recall_score(expected, predicted, average='weighted'))\n",
    "sum([v * expected_count[key] / len(expected) for key, v in results.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy for specific industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "test_industries = Counter([c['industry'] for c in tested])\n",
    "company_accuracy = defaultdict(int)\n",
    "\n",
    "for company, predict in zip(tested, predicted):\n",
    "    if company['industry'] == predict:\n",
    "        company_accuracy[company['industry']] += 1\n",
    "\n",
    "for key, item in company_accuracy.items():\n",
    "    company_accuracy[key] = round(item / test_industries[key] * 100, 2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [masters]",
   "language": "python",
   "name": "Python [masters]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
