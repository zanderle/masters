{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('companies_cross.json', 'r') as f:\n",
    "    companies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Let's use only companies that we currently have website of (at least some pages)\n",
    "companies = [c for c in companies if c.get('path_to')]\n",
    "\n",
    "# Let's also limit the number of sites (because this is not cleaned yet)\n",
    "companies = [c for c in companies if c.get('current_site_count', 0) < 100]\n",
    "\n",
    "# Let's use only well represented industries\n",
    "industries = Counter([c['industry'] for c in companies])\n",
    "companies = [c for c in companies if industries[c.get('industry')] > 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('similar_industries.json', 'r') as f:\n",
    "    similar_industries = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import logging\n",
    "\n",
    "# set root logger level\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# setup custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.FileHandler('extract_features.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def get_texts_for_domain(path, file_name):\n",
    "    text_file = os.path.join(path, file_name)\n",
    "    if not os.path.exists(text_file):\n",
    "        text = None\n",
    "        text_file = '/dev/null'\n",
    "    else:\n",
    "        with open(text_file, 'r') as f:\n",
    "            text = f.read()\n",
    "    return text, text_file\n",
    "\n",
    "\n",
    "def get_full_text(path):\n",
    "    return get_texts_for_domain(path, 'full_texts.txt')\n",
    "\n",
    "\n",
    "def get_nav_text(path):\n",
    "    return get_texts_for_domain(path, 'nav_menu.txt')\n",
    "\n",
    "\n",
    "def get_meta_descriptions_text(path):\n",
    "    return get_texts_for_domain(path, 'descriptions.txt')\n",
    "\n",
    "\n",
    "def get_meta_keywords_text(path):\n",
    "    return get_texts_for_domain(path, 'keywords.txt')\n",
    "\n",
    "\n",
    "def get_titles_text(path):\n",
    "    return get_texts_for_domain(path, 'titles.txt')\n",
    "\n",
    "\n",
    "def get_metas_text(path):\n",
    "    return get_texts_for_domain(path, 'metas.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_similar(estimator, data, actual):\n",
    "    predict = estimator.predict(data)\n",
    "#     actual = [c['industry'] for c in actual]\n",
    "    expected_count = Counter(actual)\n",
    "    results = {}\n",
    "    for num, example in enumerate(actual):\n",
    "        if example == predict[num]:\n",
    "            results[example] = results.get(example, 0) + 1\n",
    "        elif predict[num] in similar_industries.get(example, []):\n",
    "            results[example] = results.get(example, 0) + 0.5\n",
    "\n",
    "    for key, value in results.items():\n",
    "        results[key] = value / expected_count[key]\n",
    "\n",
    "#     print(recall_score(expected, predicted, average='weighted'))\n",
    "    return sum([v * expected_count[key] / len(actual) for key, v in results.items()])\n",
    "\n",
    "\n",
    "def score_similar_single(estimator, data, actual):\n",
    "    predict = estimator.predict(data)\n",
    "#     actual = [c['industry'] for c in actual]\n",
    "    expected_count = Counter(actual)\n",
    "    results = {}\n",
    "    for num, example in enumerate(actual):\n",
    "        if example == predict[num]:\n",
    "            results[example] = results.get(example, 0) + 1\n",
    "        elif predict[num] in similar_industries.get(example, []):\n",
    "            results[example] = results.get(example, 0) + 0.5\n",
    "\n",
    "    for key, value in results.items():\n",
    "        results[key] = value / expected_count[key]\n",
    "    return results\n",
    "\n",
    "sizes = {\n",
    "    '1': 1,\n",
    "    '1-10': 2,\n",
    "    '11-50': 3,\n",
    "    '51-200': 4,\n",
    "    '201-500': 5,\n",
    "    '501-1000': 6,\n",
    "    '1001-5000': 7,\n",
    "    '5001-10,000': 8,\n",
    "    '10,001+': 9,\n",
    "}\n",
    "\n",
    "def scoring_neighbour(estimator, data, actual):\n",
    "    predicted = estimator.predict(data)\n",
    "    correct = 0\n",
    "    for p, a in zip(predicted, actual):\n",
    "        if abs(sizes.get(p) - sizes.get(a)) < 2:\n",
    "            correct += 1\n",
    "    return correct/len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create transformers\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_from_company(companies, func):\n",
    "    paths = []\n",
    "    for company in tqdm(companies):\n",
    "        text, path = func(company['path_to'])\n",
    "        paths.append(path)\n",
    "    return paths\n",
    "\n",
    "def get_full_text_from_company(companies):\n",
    "    return extract_from_company(companies, get_full_text)\n",
    "\n",
    "def get_nav_menus_from_company(companies):\n",
    "    return extract_from_company(companies, get_nav_text)\n",
    "\n",
    "def get_descriptions_from_company(companies):\n",
    "    return extract_from_company(companies, get_meta_descriptions_text)\n",
    "\n",
    "def get_titles_from_company(companies):\n",
    "    return extract_from_company(companies, get_titles_text)\n",
    "\n",
    "def get_keywords_from_company(companies):\n",
    "    return extract_from_company(companies, get_meta_keywords_text)\n",
    "\n",
    "def get_metas_from_company(companies):\n",
    "    return extract_from_company(companies, get_metas_text)\n",
    "\n",
    "\n",
    "full_text_transformer = FunctionTransformer(get_full_text_from_company, validate=False)\n",
    "nav_menus_transformer = FunctionTransformer(get_nav_menus_from_company, validate=False)\n",
    "descriptions_transformer = FunctionTransformer(get_descriptions_from_company, validate=False)\n",
    "titles_transformer = FunctionTransformer(get_titles_from_company, validate=False)\n",
    "keywords_transformer = FunctionTransformer(get_keywords_from_company, validate=False)\n",
    "metas_transformer = FunctionTransformer(get_metas_from_company, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from numpy import concatenate\n",
    "\n",
    "hv = HashingVectorizer(non_negative=True, input='filename')\n",
    "tfv = TfidfVectorizer(input='filename', max_features=3000)\n",
    "tf_transformer = TfidfTransformer()\n",
    "# clf = SGDClassifier(loss='hinge', penalty='l2', n_iter=10, alpha=0.001, n_jobs=10)#, class_weight='balanced')\n",
    "clf2 = SGDClassifier(loss='hinge', n_iter=10, alpha=0.001, n_jobs=10)#, class_weight='balanced')\n",
    "lda = LatentDirichletAllocation(n_topics=100, learning_method='batch', max_iter=5, n_jobs=5, learning_offset=50.)\n",
    "st_clf = SGDClassifier(loss='hinge', penalty='l2', n_iter=10, alpha=0.001, n_jobs=10)\n",
    "st_clf2 = SGDClassifier(loss='log', penalty='l2', n_iter=10, alpha=0.001, n_jobs=10)\n",
    "lsa = TruncatedSVD(n_components=100)\n",
    "\n",
    "# pipeline_elements = [('HV', hv), ('tfid', tf_transformer), ('lsa', lsa), ('svc', clf)]\n",
    "pipeline_elements = [('HV', hv), ('tfid', tf_transformer), ('svc', clf)]\n",
    "pipe = Pipeline(pipeline_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to do this, to make our classifier return \"something\" with .predict_proba()\n",
    "# The default version doesn't allow that for this specific classifier\n",
    "# We need it for VotingClassifier, to enable voting='soft'\n",
    "class CustomSGD(SGDClassifier):\n",
    "    def predict_proba(self, X):\n",
    "        return self.decision_function(X)\n",
    "\n",
    "clf = CustomSGD(loss='hinge', penalty='l2', n_iter=10, alpha=0.001, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "\n",
    "pipe_full = Pipeline([('Full', full_text_transformer)] + pipeline_elements)\n",
    "pipe_nav_menus = Pipeline([('Navs', nav_menus_transformer)] + pipeline_elements)\n",
    "pipe_descriptions = Pipeline([('Descriptions', descriptions_transformer)] + pipeline_elements)\n",
    "pipe_titles = Pipeline([('Titles', titles_transformer)] + pipeline_elements)\n",
    "pipe_keywords = Pipeline([('Keywords', keywords_transformer)] + pipeline_elements)\n",
    "pipe_meta = Pipeline([('Metas', metas_transformer)] + pipeline_elements)\n",
    "\n",
    "identity = FunctionTransformer(None, validate=False)\n",
    "lda_union = FeatureUnion([('lda', lda), ('identity', identity)])\n",
    "pipe_lda = Pipeline([('Full', pipe_meta),\n",
    "                     ('tfv', tfv),\n",
    "                     ('lda_union', lda_union),\n",
    "#                      ('lda', lda),\n",
    "                     ('clf', clf2)\n",
    "                    ])\n",
    "\n",
    "\n",
    "# For some reason this is not working as it should. Explore why\n",
    "stacking = StackingClassifier(classifiers=[pipe_full,\n",
    "                                           pipe_meta],\n",
    "                             meta_classifier=st_clf, use_probas=True, average_probas=False)\n",
    "\n",
    "# Might be able to get better results with adding some other\n",
    "# estimators. Find out with GridSeachCV. Try different weights too\n",
    "voting = VotingClassifier(estimators=[('full', pipe_full),\n",
    "#                                       ('navs', pipe_nav_menus),\n",
    "#                                       ('desc', pipe_descriptions),\n",
    "#                                       ('titles', pipe_titles),\n",
    "#                                       ('keywords', pipe_keywords),\n",
    "                                      ('meta', pipe_meta),\n",
    "#                                       ('lda', pipe_lda)\n",
    "                                     ],\n",
    "                         voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell, if you want to test only on english websites\n",
    "companies_orig = companies\n",
    "\n",
    "companies = [c for c in companies if c['website_lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed only for StackingClassifier (it throws error on non-int labels...)\n",
    "target_int_map = {key: i for i, key in enumerate(industries.keys())}\n",
    "inv_target_int_map = {i: ind for ind, i in target_int_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "companies = shuffle(companies)\n",
    "\n",
    "target = []\n",
    "train_data = []\n",
    "\n",
    "for company in tqdm(companies[:-10000]):\n",
    "    text, file_name = get_full_text(company['path_to'])\n",
    "    if text:\n",
    "        train_data.append(company)\n",
    "        industry = company['industry']\n",
    "        target.append(industry)\n",
    "#         target.append(company['company_size_clean'])\n",
    "\n",
    "# int_target = [target_int_map[industry] for industry in target]\n",
    "\n",
    "# Fit\n",
    "# clf2.fit(new, target)\n",
    "\n",
    "# pipe_lda_final.fit(train_data, target)\n",
    "voting.fit(train_data, target)\n",
    "# pipe_full.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the best in stacking\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "classifiers = [pipe_full,\n",
    "                pipe_meta]\n",
    "\n",
    "for c in classifiers:\n",
    "    score_stacking = cross_val_score(c, train_data, int_target, scoring=score_similar, n_jobs=5)\n",
    "    print(score_stacking.mean())\n",
    "\n",
    "score_stacking = cross_val_score(stacking, train_data, int_target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_stacking *****\")\n",
    "print(score_stacking.mean())\n",
    "\n",
    "# params = [\n",
    "#     {'use_probas': [True, False]},\n",
    "#     {'use_probas': [True], 'average_probas': [True, False]}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the best in voting\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = [{'voting': ['hard', 'soft']},\n",
    "          {'voting': ['hard'],\n",
    "          'weights': [[1, 1, 1, 1], [2, 1.5, 1.2, 1.2], [1, 1.2, 1.2, 1], [1.5, 1, 1, 1]]}]\n",
    "params = params[0]\n",
    "\n",
    "grid = GridSearchCV(voting, param_grid=params, scoring=score_similar)\n",
    "grid.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "score_meta = cross_val_score(pipe_meta, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_meta *****\")\n",
    "print(score_meta.mean())\n",
    "# score_lda = cross_val_score(pipe_lda, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "# print(\"***** score_lda *****\")\n",
    "# print(score_lda.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "score_full = cross_val_score(pipe_full, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_full *****\")\n",
    "print(score_full.mean())\n",
    "score_nav = cross_val_score(pipe_nav_menus, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_nav *****\")\n",
    "print(score_nav.mean())\n",
    "score_titles = cross_val_score(pipe_titles, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_titles *****\")\n",
    "print(score_titles.mean())\n",
    "score_descriptions = cross_val_score(pipe_descriptions, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_descriptions *****\")\n",
    "print(score_descriptions.mean())\n",
    "score_keywords = cross_val_score(pipe_keywords, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_keywords *****\")\n",
    "print(score_keywords.mean())\n",
    "\n",
    "# params = {\n",
    "#     'voting': ['hard'],\n",
    "#     'weights': [[1, 1, 1, 1, 1], [1, 1, 1, 1, 0], [1.7, 1, 1, 1, 1], [1, 1, 0.5, 0.5, 0.5], [1, 0.5, 1, 1, 0.5]]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(voting, param_grid=params, scoring=score_similar)\n",
    "# grid.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "score_full = cross_val_score(voting, train_data, target, scoring=score_similar, n_jobs=5)\n",
    "print(\"***** score_full *****\")\n",
    "print(score_full.mean())\n",
    "\n",
    "# score_full = cross_val_score(pipe_full, train_data, target, scoring=scoring_neighbour, n_jobs=5)\n",
    "# print(\"***** score_full *****\")\n",
    "# print(score_full.mean())\n",
    "# score_nav = cross_val_score(pipe_nav_menus, train_data, target, scoring=scoring_neighbour, n_jobs=5)\n",
    "# print(\"***** score_nav *****\")\n",
    "# print(score_nav.mean())\n",
    "# score_titles = cross_val_score(pipe_titles, train_data, target, scoring=scoring_neighbour, n_jobs=5)\n",
    "# print(\"***** score_titles *****\")\n",
    "# print(score_titles.mean())\n",
    "# score_descriptions = cross_val_score(pipe_descriptions, train_data, target, scoring=scoring_neighbour, n_jobs=5)\n",
    "# print(\"***** score_descriptions *****\")\n",
    "# print(score_descriptions.mean())\n",
    "# score_keywords = cross_val_score(pipe_keywords, train_data, target, scoring=scoring_neighbour, n_jobs=5)\n",
    "# print(\"***** score_keywords *****\")\n",
    "# print(score_keywords.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the best\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "params = {\n",
    "#     'svc__penalty': ['l1', 'l2'],\n",
    "#     'svc__alpha': [0.001, 0.01, 0.1],\n",
    "#     'svc__n_iter': [5, 10, 100],\n",
    "#     'svc__class_weight': [None, 'balanced']\n",
    "#     'HV__stop_words': [None, 'english']\n",
    "#     'svc__loss': ['log'],\n",
    "#     'svc__epsilon': [0.1, 5]\n",
    "    'lsa__n_components': [90, 200]\n",
    "         }\n",
    "\n",
    "grid = GridSearchCV(pipe_meta, param_grid=params, scoring=score_similar, n_jobs=3)\n",
    "grid.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try getting something valuable out of LDA\n",
    "\n",
    "lda_params = [\n",
    "    {'tfv__max_features': [1000, 2000, 4000]},\n",
    "#     {'lda_union__lda__n_topics': [10, 50, 90]}\n",
    "    {'lda__n_topics': [10, 50, 90],\n",
    "]\n",
    "\n",
    "grid_lda = GridSearchCV(pipe_lda, param_grid=lda_params, scoring=score_similar)#, n_jobs=3)\n",
    "\n",
    "grid_lda.fit(train_data[:70000], target[:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_params ={\n",
    "    'tfv__max_features': [10000],\n",
    "#     'lda_union__lda__learning_offset': [10., 50.],\n",
    "#     'clf__alpha': [0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_lda = GridSearchCV(pipe_lda, param_grid=lda_params, scoring=score_similar)#, n_jobs=3)\n",
    "\n",
    "grid_lda.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = []\n",
    "\n",
    "for company in tqdm(companies[-10000:]):\n",
    "    text, file_name = get_full_text(company['path_to'])\n",
    "    if text:\n",
    "        test_data.append(company)\n",
    "\n",
    "target_test = [c['industry'] for c in test_data]\n",
    "# score_voting = voting.score(test_data, [c['industry'] for c in test_data])  # 39% -> 40% eng  44% adjusted\n",
    "# score_full = pipe_full.score(test_data, [c['company_size_clean'] for c in test_data])  # 52.3% -> 53.8% eng\n",
    "# nav_menus - 21%\n",
    "# descriptions - 28%\n",
    "# cutoff industries 500 - 750 - 2%\n",
    "# added lda (4000, 90) - 26%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_similar(voting, test_data, [c['industry'] for c in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a dummy estimator too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Always most frequent - 8.3%\n",
    "# Based on freq - 4.2%\n",
    "# Random 2.4%\n",
    "\n",
    "dummy = DummyClassifier(strategy='stratified', constant='Marketing and Advertising')\n",
    "dummy.fit(train_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "\n",
    "expected = [c['industry'] for c in test_data]\n",
    "predicted = pipe_full.predict(test_data)\n",
    "# predicted = ['Not' if p > 0 else 'Food & Beverages' for p in predicted_prob]\n",
    "\n",
    "print(\"Classification report for classifier:\\n%s\\n\"\n",
    "      % classification_report(expected, predicted))\n",
    "print(\"Confusion matrix:\\n%s\" % confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = score_similar_single(voting, test_data, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See results based on the industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(results.items(), key=lambda x: x[0], reverse=False):\n",
    "    print(\"%s----%.1f---%d\" % (key, value * 100, industries[key]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [masters]",
   "language": "python",
   "name": "Python [masters]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
